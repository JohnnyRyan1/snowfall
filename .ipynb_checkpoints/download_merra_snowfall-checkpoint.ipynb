{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8031d2e-825f-4f1d-b2db-88c611523590",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "1. Make main indexing dataset containing:\n",
    "    - Longitude\n",
    "    - Latitude\n",
    "    - ISMIP grid cell index\n",
    "    - Region\n",
    "    - Elevation\n",
    "\n",
    "2. Download MERRA2 data at daily interval\n",
    "\n",
    "3. Resample to ISMIP grid\n",
    "\n",
    "4. Filter snowfall rates in the ablation zone\n",
    "\n",
    "5. Save as NetCDF4\n",
    "    - Snowfall \n",
    "    - Time\n",
    "\n",
    "6. Delete original files\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Import libraries\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import netCDF4\n",
    "import pyresample\n",
    "from pyproj import Transformer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define base path\n",
    "path = '/Users/jryan4/Dropbox (University of Oregon)/research/snowfall/'\n",
    "\n",
    "# Define path to links\n",
    "links = pd.read_csv(path + 'data/links/subset_M2T1NXINT_5.12.4_19800101_20000101_Daily_PRECSN_Greenland.txt', sep='\\t', header=None)\n",
    "links.rename(columns={0: \"link\"}, inplace=True)\n",
    "links['year'] = links['link'].str[119:123]\n",
    "\n",
    "# Define years\n",
    "years = np.arange(1980, 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0010a3bd-275f-48c5-bbeb-4d1368192baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read ISMIP data\n",
    "ismip = xr.open_dataset(path + 'data/masks/1km-ISMIP6.nc')\n",
    "\n",
    "# Define maximum snowline\n",
    "snowline_file = netCDF4.Dataset(path + 'data/masks/monthly_bare_ice_2012.nc')\n",
    "snowline = snowline_file.variables['bare_ice'][1, :, :].filled(np.nan)\n",
    "max_snowline = (snowline > 0.1)\n",
    "\n",
    "# Define regions\n",
    "regions = xr.open_dataset('/Users/jryan4/Dropbox (University of Oregon)/research/clouds/data/temp_albedo_summer_climatologies.nc')\n",
    "\n",
    "# Define ablation zone coordinates, elevations, and regions\n",
    "abl_lon = ismip['lon'].values[max_snowline]\n",
    "abl_lat = ismip['lat'].values[max_snowline]\n",
    "abl_ele = ismip['SRF'].values[max_snowline]\n",
    "abl_reg = regions['regions'].values[max_snowline]\n",
    "\n",
    "# Indices of ablation zone\n",
    "idx, idy = np.where(max_snowline)\n",
    "\n",
    "# Define MERRA data\n",
    "merra_file = xr.open_dataset(path + 'data/merra_sample/MERRA2_200.tavg1_2d_int_Nx.20000101.SUB.nc')\n",
    "\n",
    "# Meshgrid lat/lons\n",
    "merra_mesh_lon, merra_mesh_lat = np.meshgrid(merra_file['lon'], merra_file['lat'])\n",
    "\n",
    "# Define grid definitions for resampling to ISMIP grid\n",
    "orig_def_regions = pyresample.geometry.GridDefinition(lons=merra_mesh_lon, lats=merra_mesh_lat)\n",
    "targ_def = pyresample.geometry.GridDefinition(lons=ismip['lon'], lats=ismip['lat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d370bb3d-f6ec-4db2-a6e5-a6bd9292f1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save main indexing dataset\n",
    "ds_main = xr.Dataset(\n",
    "    data_vars={\n",
    "        \"region\": ((\"x\"), np.array(abl_reg).astype('int8')),\n",
    "        \"elevation\": ((\"x\"), np.array(abl_ele).astype('float64')),\n",
    "        \"index_x\": ((\"x\"), np.array(idx).astype('int16')),\n",
    "        \"index_y\": ((\"x\"), np.array(idy).astype('int16')),\n",
    "    },\n",
    "    \n",
    "    coords={\n",
    "        \"longitude\": (('x',), np.array(abl_lon)),\n",
    "        \"latitude\": (('x',), np.array(abl_lat)), \n",
    "    },\n",
    "    attrs={\n",
    "        \"Produced\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"Author\":'Johnny Ryan', \n",
    "        \"Email\":'jryan4@uoregon.edu'\n",
    "    },\n",
    ")\n",
    "\n",
    "ds_main.to_netcdf(path + 'data/masks/index_main.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a981ea2-78e6-4842-bde6-a55f20ff692d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Mismatch between geometry and dataset",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/xj/5ps5mr8d5ysbd2mxxqjg3k800000gq/T/ipykernel_63906/2354682775.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;31m# Determine nearest (w.r.t. great circle distance) neighbour in the grid.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             snow_resample = pyresample.kd_tree.resample_nearest(source_geo_def=orig_def_regions, \n\u001b[0m\u001b[1;32m     31\u001b[0m                                                          \u001b[0mtarget_geo_def\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarg_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                                                          \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmerra\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PRECSN'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/clouds/lib/python3.8/site-packages/pyresample/kd_tree.py\u001b[0m in \u001b[0;36mresample_nearest\u001b[0;34m(source_geo_def, data, target_geo_def, radius_of_influence, epsilon, fill_value, reduce_data, nprocs, segments)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mSource\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mresampled\u001b[0m \u001b[0mto\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mgeometry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \"\"\"\n\u001b[0;32m--> 104\u001b[0;31m     return _resample(source_geo_def, data, target_geo_def, 'nn',\n\u001b[0m\u001b[1;32m    105\u001b[0m                      \u001b[0mradius_of_influence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneighbours\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                      \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/clouds/lib/python3.8/site-packages/pyresample/kd_tree.py\u001b[0m in \u001b[0;36m_resample\u001b[0;34m(source_geo_def, data, target_geo_def, resample_type, radius_of_influence, neighbours, epsilon, weight_funcs, fill_value, reduce_data, nprocs, segments, with_uncert)\u001b[0m\n\u001b[1;32m    265\u001b[0m                            segments=segments)\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     return get_sample_from_neighbour_info(resample_type,\n\u001b[0m\u001b[1;32m    268\u001b[0m                                           \u001b[0mtarget_geo_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m                                           \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_input_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/clouds/lib/python3.8/site-packages/pyresample/kd_tree.py\u001b[0m in \u001b[0;36mget_sample_from_neighbour_info\u001b[0;34m(resample_type, output_shape, data, valid_input_index, valid_output_index, index_array, distance_array, weight_funcs, fill_value, with_uncert)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalid_input_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mismatch between geometry and dataset'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m     \u001b[0mis_multi_channel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Mismatch between geometry and dataset"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "# Loop over every link and append a 1D array of ablation zone snowfall + time\n",
    "for year in years:\n",
    "    \n",
    "    if os.path.exists(path + 'data/merra/ablation_snowfall_' + str(year) + '.nc'):\n",
    "        print(f'Skipping...{str(year)}')\n",
    "    else:\n",
    "        print(f'Processing...{str(year)}')\n",
    "        # Make a new DataFrame\n",
    "        link_year = links[links['year'] == str(year)]\n",
    "\n",
    "        t = []\n",
    "        snowfall = []\n",
    "        for j in range(len(link_year)):\n",
    "\n",
    "            # Index link\n",
    "            link = '\"' + str(link_year.iloc[j].values[0]) + '\"'\n",
    "\n",
    "            # Download MERRA2 using WGET\n",
    "            !wget --load-cookies ~/.urs_cookies --save-cookies ~/.urs_cookies --auth-no-challenge=on --keep-session-cookies --no-check-certificate --content-disposition $link --directory-prefix=tmp_sf -nd\n",
    "\n",
    "            # Import temporary file\n",
    "            merra = xr.open_dataset(sorted(glob.glob(path + 'repo/tmp_sf/*.nc'))[0])\n",
    "            \n",
    "            # Clean up temporary files\n",
    "            files = glob.glob(path + 'repo/tmp_sf/*.nc')\n",
    "            for f in files:\n",
    "                os.remove(f)\n",
    "\n",
    "            # Determine nearest (w.r.t. great circle distance) neighbour in the grid.\n",
    "            snow_resample = pyresample.kd_tree.resample_nearest(source_geo_def=orig_def_regions, \n",
    "                                                         target_geo_def=targ_def, \n",
    "                                                         data=np.mean(merra['PRECSN'].values, axis=0), \n",
    "                                                         radius_of_influence=50000)\n",
    "\n",
    "            # Append to list\n",
    "            snowfall.append(snow_resample[max_snowline])\n",
    "            t.append(merra['time'].values[0])\n",
    "\n",
    "        # Save as NetCDF\n",
    "        ds_data = xr.Dataset(\n",
    "        data_vars={\n",
    "            \"snowfall\": ((\"time\", \"x\"), np.array(snowfall).astype('float32')),\n",
    "        },\n",
    "\n",
    "        coords={\n",
    "            \"time\": pd.DatetimeIndex(t, freq='D'),\n",
    "            \"longitude\": (('x',), np.array(abl_lon)),\n",
    "            \"latitude\": (('x',), np.array(abl_lat)),    \n",
    "        },\n",
    "\n",
    "        attrs={\n",
    "            \"Produced\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"Units\": 'kg m-2 s-1',\n",
    "            \"Author\":'Johnny Ryan', \n",
    "            \"Email\":'jryan4@uoregon.edu'\n",
    "        },\n",
    "        )\n",
    "\n",
    "        # Save\n",
    "        ds_data.to_netcdf(path + 'data/merra_snowfall/ablation_snowfall_' + str(year) + '.nc')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfb646b-aef0-4899-9230-1ee5844896f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
